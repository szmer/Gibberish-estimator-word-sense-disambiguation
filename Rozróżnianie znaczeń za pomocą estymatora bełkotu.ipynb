{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_file = \"/home/szymon/lingwy/nkjp/nkjp_index.txt\"\n",
    "nkjp_path = \"/home/szymon/lingwy/nkjp/pełny/\"\n",
    "vecs_path = \"/home/szymon/lingwy/nkjp/wektory/nkjp+wiki-lemmas-all-100-skipg-ns.txt/\"\n",
    "skladnica_sections_index = \"/home/szymon/lingwy/nkjp/skladnica_znacz/sections.txt\"\n",
    "skladnica_path = \"/home/szymon/lingwy/nkjp/skladnica_znacz/\"\n",
    "vecs_dim = 100\n",
    "window_size = 4 # how many words to condider on both sides of the target\n",
    "batch_size = window_size * 2\n",
    "corp_runs = 2\n",
    "learning_rate = 0.3\n",
    "reg_rate = 0.005\n",
    "points_per_neg_sample = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get all the fragments present in Składnica.\n",
    "from operator import itemgetter\n",
    "skladnica_sents = set()\n",
    "\n",
    "with open(skladnica_sections_index) as index:\n",
    "    for section_name in index:\n",
    "        sectpath = skladnica_path + section_name.strip()\n",
    "        # Earch section has 1+ dirs of XML files.\n",
    "        for dirname, _, __ in os.walk(sectpath):\n",
    "            if dirname != sectpath: # ignore the dir itself\n",
    "                # Get the XML files (each contains a sentence)\n",
    "                for _, __, filenames in os.walk(dirname):\n",
    "                    for filename in filenames:\n",
    "                        tree = etree.parse(dirname+'/'+filename)\n",
    "                        skladnica_sents.add(tree.find(\".//text\").text.replace(' ', ''))\n",
    "#                        sent = []\n",
    "#                        for elem in tree.iterfind('node[@chosen]'):\n",
    "#                            if elem.attrib['chosen'] == 'true' and elem.find(\"terminal\") is not None:\n",
    "#                                sent.append((int(elem.attrib['from']),\n",
    "#                                             elem.find(\"terminal\").find(\"orth\").text))\n",
    "#                        sent.sort(key=itemgetter(0))\n",
    "#                        sent = [token for num, token in sent]\n",
    "#                        skladnica_sents.add(''.join(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Edit (Levenshtein) distance\n",
    "from nltk.metrics import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zatrzasnąłdrzwiodmieszkania,dwarazyprzekręciłklucz,nacisnąłklamkę,bysprawdzić,czydobrzezamknięte,zbiegłposchodach,minąłfurtkę,takżejązamknął,iznalazłsięnawąskiejuliczcemiędzyogródkami,gdziedrzemaływmajowymsłońcutrójkątneciemnozieloneświerki,jakichniebyłowpobliżujegodomu. --- Zatrzasnął drzwi od mieszkania, dwa razy przekręcił klucz, nacisnął klamkę, by sprawdzić, czy dobrze zamknięte, zbiegł po schodach, minął furtkę, także ją zamknął, i znalazł się na wąskiej uliczce między ogródkami, gdzie drzemały w majowym słońcu trójkątne ciemnozielone świerki, jakich nie było w pobliżu jego domu.\n",
      "BohaterempowieściPaźniewskiegojestmiasto,Krzemieniec. --- Bohaterem powieści Paźniewskiego jest miasto, Krzemieniec.\n",
      "JakzaczasówSłowackiegofunkcjonujeLiceumipłynieIkwa. --- Jak za czasów Słowackiego funkcjonuje Liceum i płynie Ikwa. Krzemieniec powieściowy jest tamtym Krzemieńcem, ale jest także miastem wywołanym z osobistej pamięci Paźniewskiego. Swoją drogę do tego miasta autor \"Krótkich dni\" zaczął z bardzo daleka. \"Nigdy nie byłem w tym domu, a przecież wszystko pamiętam doskonale\".\n",
      "KrzemieniecpowieściowyjesttamtymKrzemieńcem,alejesttakżemiastemwywołanymzosobistejpamięciPaźniewskiego. --- Ale dzisiaj? Jaką dzisiaj odegra rolę poetyka Przybosia? Oczywiście, już sam fakt jej istnienia jest wartością. Nasza literatura, bogata w improwizacje i w akty strzeliste, jest uboga w teorie. Rolę teoretyków spełniają felietoniści, którzy co tydzień fundują szkoły i formułują programy. Dlatego założenia teoretyczne Przybosia obok teorii Peipera i Witkacego, a równolegle do propozycji systemów Irzykowskiego i Sandauera, stanowią kapitał naszej myśli krytycznej, naturalny fundament każdej twórczości. To są oczywistości.\n",
      "Swojądrogędotegomiastaautor\"Krótkichdni\"zacząłzbardzodaleka. --- Halina Auderska we wszystkich książkach każe swoim bohaterom szukać tożsamości. W \"Babim lecie\" ma odwagę uznać za najistotniejsze kryterium tożsamości poczucie przynależności nie do idei, nie do kultury i mitów narodowych, lecz do tego, co jest podstawą bytu każdego człowieczeństwa. Miejsce na ziemi, konkret fizyczny i społeczny jednocześnie jest tym, co stanowi o wymiarze życia i losu.\n",
      "\"Nigdyniebyłemwtymdomu,aprzecieżwszystkopamiętamdoskonale\". --- Paźniewski w \"Krótkich dniach\" ofiarował Kresom nie mniej, niż z nich zaczerpnął. Zatrzymał potop. Zamówił kataklizm. Stworzył wizję oczekiwania, wizję spokoju przed burzą. Z napięciem czekamy na chwilę, która będzie chwilą decydującą o losie bohatera. Cóż za ulga. Mija ostatnie zdanie powieści. Co za wspaniała książka! Ocalająca!\n",
      "Aledzisiaj? --- \"Plama\" Piętaka, jedna spośród kilku najznakomitszych współczesnych powieści, także ze względu na jej zaklasyfikowanie wraz z całą twórczością tego pisarza do nurtu wiejskiego, nie ma w odbiorze powszechnym tej rangi, jaką rzeczywiście posiada. Wszystko co Piętak wyniósł z chłopskiej szkoły wyobraźni, zaowocowało w \"Plamie\" najwyższą subtelnością psychologiczną, na jaką stać literaturę.\n",
      "JakądzisiajodegrarolępoetykaPrzybosia? --- To już nie są wątpliwości religijne, te wątpliwości pierwszego stopnia wtajemniczenia w sprawy świata, wątpliwości \"Nieba w płomieniach\" czy \"Jana Barois\".\n",
      "Oczywiście,jużsamfaktjejistnieniajestwartością. --- Tu nie chodzi o sensowność dogmatów czy ścisłość religijnych wyobrażeń, nie chodzi już o religię, o tajemnicę stworzenia, ale o normę etyczną. Kto ją ustanowi, kiedy Boga zabrakło?\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e0780425d612>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_forms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mfinal_form\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_forms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0morig_form\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_orig_sents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msent_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_form\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'---'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_form\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0;31m#if 'młodzieży' in sent_forms:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Read the NKJP fragments, as lists of lemmas\n",
    "unique_words = set()\n",
    "words_count = 0\n",
    "fragms = []\n",
    "rejected_sents = []\n",
    "\n",
    "with open(index_file) as index:\n",
    "    for fragm_id in index:\n",
    "        text_filepath = nkjp_path+fragm_id.strip()+'/text.xml'\n",
    "        if not os.path.isfile(text_filepath):\n",
    "            print('Note: cannot access {}'.format(fragm_id.strip()))\n",
    "            continue\n",
    "        tree = etree.parse(text_filepath)\n",
    "        local_orig_sents = []\n",
    "        for orig_sent_tag in tree.iterfind('.//{http://www.tei-c.org/ns/1.0}ab'):\n",
    "            local_orig_sents.append(orig_sent_tag.text)\n",
    "        \n",
    "        # tag is namespaced, .// for finding anywhere in the tree\n",
    "        tokens_filepath = nkjp_path+fragm_id.strip()+'/ann_morphosyntax.xml'\n",
    "        if not os.path.isfile(tokens_filepath):\n",
    "            print('Note: cannot access {}'.format(fragm_id.strip()))\n",
    "            continue\n",
    "        tree = etree.parse(tokens_filepath)\n",
    "        sent_i = -1\n",
    "        for sent_subtree in tree.iterfind('.//{http://www.tei-c.org/ns/1.0}s'):\n",
    "            sent_i += 1\n",
    "            \n",
    "            sent_forms = []\n",
    "            sent_lemmas = []\n",
    "            for elem in sent_subtree.iterfind('.//{http://www.tei-c.org/ns/1.0}f[@name]'):\n",
    "                if elem.attrib['name'] == 'base':\n",
    "                    sent_lemmas.append(elem[0].text) # first child <string>\n",
    "                if elem.attrib['name'] == 'orth':\n",
    "                    sent_forms.append(elem[0].text)\n",
    "            if len(sent_forms) > 0:\n",
    "                final_form = ''.join(sent_forms).replace(' ', '')\n",
    "                orig_form = local_orig_sents[sent_i]\n",
    "                print(final_form, '---', orig_form)\n",
    "                #if 'młodzieży' in sent_forms:\n",
    "                #    print(sent_forms)\n",
    "                ##for skl_sent in skladnica_sents: # check all known skladnica sents\n",
    "                    # allow at most every 30th character to be changed due to corpus corrections:\n",
    "                    ##distance_allowed = (len(skl_sent) + len(final_form)) / 2 / 30\n",
    "                    ##if (len(skl_sent) > 0\n",
    "                        ##and abs(len(skl_sent) - len(final_form)) < distance_allowed # limit edit dist. tries\n",
    "                        ##and distance.edit_distance(skl_sent, final_form) < distance_allowed):\n",
    "                        #if skl_sent in rejected_sents:\n",
    "                        #    print('Repeated: ', skl_sent)\n",
    "                if final_form in skladnica_sents or orig_form in skladnica_sents:\n",
    "                    rejected_sents.append(skl_sent)\n",
    "                    ##break\n",
    "                else:\n",
    "                    fragms += [[]]\n",
    "                    for word in sent_lemmas:\n",
    "                        fragms[-1].append(word)\n",
    "                        words_count += 1\n",
    "                        unique_words.add(word)\n",
    "print('{} individual sents rejected, for {} known from test corpus'.format(len(rejected_sents), len(skladnica_sents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Półrokutemu\"Fakty\"miały25–30proc.udziałówwrynkuwidowni,cooznacza,żena100włączonychtelewizoróww30leciały\"Fakty\".\n",
      "Powstajepytanie,czytegorodzajunagromadzenieznamiennegośrodkajęzykowo­stylistycznegostanowiosobisteodkryciepoetyckieWładysławaBroniewskiego,czyteżwjakiśsposóbdzielionjezewspółczesnymi.\n",
      "Podejrzewam,żenamojejtwarzypojawiłsięuśmiechsugerującynietylelekceważenie,coskrajnysceptycyzm,bozapytał:-Niewierzyojciecwto,ześredniowieczestanowidlanaswciążwielkąniewiadomą?\n",
      "Wrezu1taciezpoczątkowych25tysięcyizotrzymanychzsumwłoskich12tysięcyzostałowkasie350funtów.\n",
      "Ato,żezdecydowałsiępracowacprzedkamerąświadczyojegoodwadze.\n",
      "Chodziolata1870–1914,wiemtylko,żewtedywłasniepowstawałyfabryki,główniewłokienniczewtymmieście.\n",
      "Zapierwszymrazem-zautokaru,któryodjechałbezemniwracałemdoWarszawypierwszych,wojennychnocy.\n",
      "Roku1960stanowiokazjedoprzypomnieniasobiezmian,jakiezaszłyprzezostatnie10lat.\n",
      "Program\"Nieletniaprawo\"adresowanyjestprzedewszytskimdouczniówgimnazjów,jegocelemjestprzekazaniemłodzieżywprzystęnysposóbwiedzynatematodpowiedzialnościzapopełnianieczynówniezgodnychzprawem.\n",
      "Polacyzjadajązaledwie2,7litralodówrocznie,Węgrzy4,31,zaśrekordzistamisąAmerykanie(221itrów).\n",
      "Niżejpodajemyopinieusasadniającenegatywnywpływzłejorganizacjipracynadyscyplinęczasupracy.\n",
      "Zfizjologicznegopunktuwidzeniaczłowiekmożedożyć120–140lat,nieprzyjmującżadnychśrodkówfarmakologicznych.\n",
      "Oszczędnościprywatnenetto(gospodarstwdomowychiprzedsiębiorstw)kształtowałysięstalenawysokimpoziomieiwzrastaływstosunkudoPNB-od9,9%PNBprzeciętniewlatach1952–1954do19,7%wlatach1970–1972(por.tabela6.1);przyczympodstawoweznaczenieposiadałyoszczędnościludności(6,7%i13,4%-odpowiedniowbadanychokresach).\n",
      "NaulicachPetresburgapojawiłysięgrupy,przybyłychzKronsztadu,marynarzy.\n",
      "Policjaprosiosoby,któremogąpomócwjegoidentyfikacjiokontaktznr.telefonu635–25-00.\n",
      "Młodzizamieszkalinaul.Chrobrcgo.\n",
      "GajewskiStanisław(1912–199?).\n",
      "Wysłużonywachmistrz,certyfikatysta,biłwnichkasarnianymsłtiwemjakpięścią,którateżbyłanieodparady.\n",
      "Zarządpozwoliłteżsobienawieleobraźliwychepitetów,anawetkłamstwwobecredakcji,zarzucającjejtendencyjnośćibarkobiektywizmu.\n",
      "Wceluuzyskaniadowodówrzeczowychpoddanodoekspertyzysadowejśladykrwi,ubraniaiinnezabezpieczoneprzedmioty.\n",
      "NastarymtankowcuM/sM\"Norsel\"nanogachsątylkorosyjscymarynarzeipanMarek,polskikucharz,któryznakomiciegotuje.\n",
      "ZapisywsekretariacieGDKprzyul.Słowackiego1lubpodnumerem418–26-88.\n",
      "-Tupotrzebnyjestktośmłody,energicz–ny.\n",
      "Wl.1951–77włączonowobrębTychsamodzielnedotądjednostkiadministracyjne:Żwaków,Paprocany,Cielmice,Kobiór,Urbanowice,Jaroszowice,Bojszowy,Międzyrzecze,Jedlinę,BieruńStary,BieruńNowy,Lędziny,Hołdunów,Czułów,WartogłowieciWyry.\n",
      "Swojadrogąmożnabyprzełożyćjąnalato,możnabytłoczyćjakieśbułgarskiewinogrona,przynajmniejwinoniebyłobytakiecierpkie.\n",
      "ZaatakowaligozatosocjalistaStanisławBrzozowskizjednejstronyorazendekibezwzględnypolemistaAdolfNeuwert–Nowaczyńskizdrugiej.\n",
      "Czterylata(1963–1967)Lopekbawiłkawiarnianychgościskładankami,ograniczającsiędoaluzjidorzeczywistości,niewinnychjakoddechniemowlaka.\n",
      "Wpóźniejszychstadiachrozkład(degradacji)niszczonesąbłonykomórkowe,cozkoleipowodujeobniżenieciężaruwłaściwego,twardościdrewna;awkońcowymstadiumdrewnotraciswądotychczasowąnormalnąstrukturę..\n",
      "-NaszambasadorzażądałĘnietylkowycofaniaobraźliwychspotów,aleispecjalnegoposiedzeniazarządufirmy-opowiadaJustynaLewańskazpolskiegoMSZ.\n",
      "Nierobiliżadnychwymówek,tegodniaskończyłszkołęimyśleli,zeposzedłpożegnaćsięzkolegami.\n",
      "Ciesząsię,zektośzdecydowałsięwyciągnąćdonichpomocnądłoń.\n",
      "Gdyrozległsiękrzyk,Guilielmozakryltwarzrękami.\n",
      "Zaklęcianieskutkowałyizmęczona,spoconazaklinaczkaszepnęłaResie:-BiegnijdoAb–RamasynaTarego,niechdatabliczki,wszystkie,jakieposiada...\n",
      "Zwłaszczajakktośpiszże\"Jestemza,aleniewprzypadku,kiedyciążabyłaplanowana\".\n",
      "Podejrzewamżeprzytypowychkosztachprodukcjitakichwytłoczekplastikowychproducentzarabiapewnie95–98%.\n",
      "Innasprawa,żesąludzie,dlaktórychcalymżyciemjestszukanienakażdymkrokujakiśpotknięcibłędównaszychkapłanów,krytykująckażdeichposunięcie-takapostawaraczejniejestobiektywnaibardzomniedenerwuje.\n",
      "BenedyktynMateuszParis(ok.1200–1259)wspomniał,żepootwarciugrobuhrabiegoPembrokew1240rokuokazałosię,żejegozwłokiznajdująsięwstaniedalekoposuniętegorozkładuiobrzydliwieśmierdzą,iuznałtozadowódjegowielkiejgrzesznościzażycia.\n",
      "PierwszapoNoblukarteczka–kolażjestz24.II.1993iprzedstawiaurocządużąmałpęzpodpisem\"mójnowyimage\".\n",
      "CzyżbytaświniabyłacenniejszawTwoimmniemaniuodmatki,córki,dziewczynyiChinczykarazemwziętych?\n",
      "Zachęcany,abyrównieżwczasieWielkiegoTygodniazrezygnowaćzoglądaniatelewizji.\n",
      "Popomalowanymwpionowe,turkusowo–białepasyprzedpokojukręciłsięzaburzonyBłażej.\n",
      "Wkontekścietejwypowiedzipostawmyniecoszerszepytanie:Czyciekawośćizainteresowaniesprawamiseksu,pragnieniaseksualne,którebudząsięwmłodymczłowieku,mogąbyćocenianiejakonieczystelubzłe?\n",
      "ŻadnazpartiiserbskiejrepublikiBośninieuzyskałowystarczającejwiększości,bysamodzielnierządzić-wynikazewstępnychwynikówwyborów.\n",
      "Dobra–noc.\n",
      "Pilocipoangielsku,francuskuiniemieckutakinformująwycieczkiprzytympomniku:\"OtopomnikpolskiegobohaterskiegogenerałaJózefaBema,uczestnikawalkpowstańczychnaWęgrzechwlatach1848–49,rozsławianegopięknymiwierszaminaszegopoetySandoraPetöfiego\".\n",
      "Natychmiastpotemzastosowaćsztuczneoddychaniemetodąusta–usta.\n",
      "Dlaporówniania:limitykwotowedlazwracanegoVAT-uwprzypadkumateriałówodliczonychwramachulgitoodpowiednio:16,6tys.zł(wprzypadkunowobudowanychdomów)i7,1tys.zł(przyremoncie).\n",
      "Trzeciatura(13­23I)obfitowałajeszczewdyskusjęnadnieuzgodnionymidokońcaart.2,3orazart.4dotyczącymzobowiązańobustronztytułuzawartychdotychczasumówmiędzynarodowych;próbowanoteżznaleźćostatecznąformułędotyczącąrozwiązywaniasporów,uzgodnićsprawęratyfikacjipaktuiterminujegoobowiązywania.\n",
      "ZresztąsamliderkonfederatówAdamSłomkapodnositakieargumentyizapowiada,zebędziedomagałsiędyskusjiorealizacjiprogramuAWSikoniecznościrekonstrukcjirządu.\n",
      "PierwszahistorycznawzmiankaoteatrzecienizwiązanajestzlegendąoukochanejcesarzaWudiipojawiasięwkronicePółnocnejDynastiiSong(960–1127).\n",
      "Wiecpojakacholeręskarżyszmisietutaj,ktocozaczął?\n",
      "StosujesięwtymceluSDS(np.0,4%),aspośródniejonowychdetergentównajczęściejTritonX-100(0,25­1%)oraztzw.podwójnydetergentwedług[159],tj.mieszaninędeoksycholanusodu(0,43%)iTween40(0,86%).\n",
      "Przypomnijmy,zewcześniejmieszkaliwstuletnim,drewnianymdomu,krytymstrzechą,przyulicyMłyńskiej.\n",
      "Przeciezsamnapisałeśzeboszewikiem.\n",
      "Horti2000totakżeokazjadozapoznaniasięznajnowocześniejszymisprzętamiogrodowymi,niezbędnyminawozami,któresprawiają,zenaszadziałkabędzieobiektemzachwytu.\n",
      "A**D***L*ZygmuntWaliszewski(1897–1936)\n",
      "Rzecznikprzyznała,zeministerstwageneralniekrytykujązałożeniaprzygotowaneprzezministrafinansówJarosławaBauca.\n",
      "WprzyszłościzprogramuPHAREorazdwóchnowychprogramów-ISPA(Wdziedzinieochronyśrodowiskaitransportu)iSAPARD(wdziedzinierolnictwairozwojuobszarówwiejskich)Polskabędziemogłauzyskaćnawet3–4-krotniewyższąpomoc.\n",
      "Wgrudniu1992roku,potrzechmiesiącach,HoneckerzostałzwolnionyprzezsądwBerliniezawzględówhumanitarnych.\n",
      "Jeslibyktośznałjakąściekawąpublikację,proszęopodanietytułuiautora.\n",
      "Narazie,przezIkwartał1998r.-jakzdecydowałrząd-cenyenergiicieplnejniemająwzrosnąćwięcejniżook.8proc.(wtym5proc.zpowodupodwyższenieVAT).\n",
      "Przed6latwLudowo-DemokratycznejRepubliceJemenuwprowadzononowepraworodzinne.\n",
      "Otow1957rokuzkolei-będącjużczłonkiemSamorząduRobotniczegonaŻeraniu-opublikowaniemwgazeciezakładowejpewne\"przemyśleniaoddalone\",odniesionedosprawyfunkcjonowanianaszegoówczesnegosamorządufabrycznego.\n",
      "TaktoprzynamniejwynikazdanychstatystycznychzebranychprzezKomendęWojewódzkąPolicjiwSzczecinie.\n",
      "Po6–8miesiącachmłodeopuszczakryjówkę.\n",
      "Wpewnymmomenciestwierdzili,zesynaniewidać.\n",
      "DziadkawięzionodoAuschwitzjakonumer14080.\n",
      "Sezonnadpolskimmorzemtrwa8–10tygodni.\n",
      "Zazwyczajsątoich6­9-letnisynowie,którychtrzebawyżywić.\n",
      "-Decyzjęowyjeździepodjęłamkrótkopowprowadzeniustanywojennego.\n",
      "-WzoremjestpremierMacinkiewicz.\n",
      "Najważniejszepracenaukowe:TechniquesofSatire;TheCaseodSaltykov-Shchedrin,TakingPenguinstotheMovies.EthnicHumoriRussia.\n",
      "-Zastaliśmyzetrzydzieściosób:urzędnicy,inteligencja,członkowieTowarzystwaIndyjsko–Węgierskiego.\n",
      "Podkreślasię,zebyłonnajlepszymrozgrywającymligiiojcemdominacjiChicagoFirewrozgrywkachgrupowych.\n",
      "Przeznajbliższe6–8miesięcySiemensnieplanujewfabrykachwiększychzmian-matobyćczasnaznalezieniezakładomnowychproduktów.\n",
      "PrzywyjeździedoWielkiejBrytanii,IrlandiiczynaMaltęzwierzęmusibyćodrobaczoneitrzebamupodaćśrodkiprzeciwkleszczowena24–48godzinprzedwyjazdem.\n",
      "ObiewspółpracowałyzPrince'emwlatach1983–1987,równoleglepróbującwystartowaćzwłasnąkarierą.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obiektjestjużgotowy,obsadanajprawdopodobniejteżskompletowa,już22lipca(odgodz.8.00)będziewięcmożnazamówićpierwszeMc-danie.\n",
      "PolskiAutokefalicznyKościółPrawosławnyzłożył15Owniosków,zktórychdotychczaszałatwiono50.\n",
      "Ostatecznadecyzjabędzierównieżzależałaodsytuacjibojowej,wtakiejznajdziesiębatalion.\n",
      "Zerkasznagrafikiwidzisz,zedzisiajtojegoobowiązek.\n",
      "WtejsytuacjinajlepsząkandydatkąneprezydentapowinnabyćAnnaRogowska,tyczkarka...\n",
      "CzterykoncertzagranaOpolszczyźniekultowajużgrupa\"StareDobreMałżeństwo\".\n",
      "Połączenieideałówrobotniczych,staregoduchakomunardów,maszerowanianabarykadyzesztandarem,zwrażliwościąnarodową,religijną,tradyconalistyzną-toniejestudanasynteza.\n",
      "PLUTONWLWIE-Przebywałwlatach1938–1957.\n",
      "13listopada1938podyktowałalistdoEdwardaChmielarczyka:ObrazymojeprzesłanenaXXI–sząBiennaledoWenecjiwrócąwnajbliższymczasiedomnie,doParyża.\n",
      "WedługszacunkówPaństwowejAgencjiRozwiązywaniaProblemówAlkoholowych,wPolsceegzystujeok.3–4mlnludziwrodzinachzproblememalkoholowym.\n",
      "Ijaktojestz„samozwańczą\",„nieuznaną\",„buntowniczą\"republiką,zktórąwysłannicyKremlawlatach1991–1993podpisywalirozliczneumowy?\n",
      "Wlatach1918–1922iwlatachtrzydziestychgrupameteorologówkierowanaprzezV.F.Bjerknesa(1862–1951)opracowaławmiaręwszechstronniekoncepcjętworzeniasięcyklonównapograniczuróżnieskierowanychprądówwmasachpowietrzaoodmiennychcechachfizycznych.\n",
      "Tensamwidokoglądałwczoraj,przedwczoraj,przezwielepoprzednienocy.\n",
      "Oprócz15ministrówwgabinetowejburzymózgówuczestnicząprzewodniczącySPDMatthiasPlatzeckiszefbawarskiejCSUEdmunStoiber.\n",
      "Daniaodrzuciławreferendumkonwergencjezeurozone.\n",
      "GdybywięcPKPiPKStalkzorganizowałyswojąpracę,żebyrybajaknajszybciejmogłabyćprzewożona,zpewnościąskorzystałabynatymgospodarkarybna,skorzystałbykonsument.\n",
      "opróczreferatówkonkurspolegałtakżenazorganizowaniusesjiposterowej(pracewformieplakatów).\n",
      "Następnąwyróżniającąsięwtymuszeregowaniuprzyczynąabsencjinieusprawiedliwionejsąniskiepłaceiłątwośćuzyskaniainnejpracy.\n",
      "Przejazdykolejowepomalowanonaprzyjemnydlaokabłękitnykolor(comapoprawićnastrójiodpędzićczarnemyśli),anaperonachustawionolustra(któremajazachęcaćdospojrzeniazasiebieizastanowienia,czywartotargnąćsięnażycie).\n",
      "OPompeipowiedziałnamchybawszystkacowiedziałicosampoznał.\n",
      "-Naróżnychetachswojegożyciaparałemsięróżnymizajęciami,alewzasadzierobiłemtosamo-działałemnaniekorzyśćimperiumsowieckiegoinarzeczniepodległościpaństwapolskiego.\n",
      "Pracezostałyjużukończone,dziurawjezdnizasypana,aruchnacałejszerokościjedni-wznowiony.\n",
      "Alemożesięmydlę.\n",
      "Pierwszewhistoriipolskiegosportumasoweimprezy—BiegiNarodowe,MarszeSzlakamiZwycięstwiprzedewszystkimMłodzieżowaSztafetaPrzedkongresowa—wlałynowątreśćznasząkulturęfizycznąizaktywizowałysetkitysięcyludzipracyiuczącejsięmłodzieży.\n",
      "Jużdzisiajcisamiświadczeniobiorcy,otrzymalidrugąprzesyłkę,wktórejbyłodcinekswiadczenia(np.renty).\n",
      "Aprzecieżmuszezapłacićludziom,ZUS,podatki...-mówiJ.Weretka.\n",
      "Tylkotyle,kiedytraciszgruntpodnogamiazdenerwowanieniepozwalanaspokojnąirzeczowąodpowiedz?\n",
      "Zetymrazemniesątoćwiczeniawięźniowieprzekonalisięnadranem,gdyusłyszeliwybuchybombisalwyartyleriiprzeciwlotniczej.\n",
      "PremierTomaszewskiprzyrzekł,zedarbędzieozdabiałagabinetpremierawsiedzibieUrzęduRadyMinistrów.\n",
      "WstyluwolnymzwyciężyłAKZBialogardprzedZKSBrokiemKoszaliniGórnikiemŁęczna.\n",
      "Badaniealkomatemwykazało,zebyłtrzeźwy.\n",
      "NatomiastRadaPaństwaNRDpodjęładecyzjapodpisaniaukładu.\n",
      "Jakiekozłyijelenie–bykiuważasięzałowne?\n",
      "Mówi,zezrobimystudzienkęisiętopodłączydokanalizy.\n",
      "Oznaczato,żeporakukalendarzowymnienagannejpracynabywaprawodonagrody,wwysokości50proc.\n",
      "Posełwl.1997–2001.\n",
      "Wówczaskobietywwieku50–69latbędąmogłyprzejśćbadaniemammograficznewykonaneprzezspecjalistówzZachodniopomorskigoCentrumOnkologii.\n",
      "Społeczeństwodomagasię,żebyczłonkowieEpiskopatuswojączynnapostawąwobroniepokojuprzekreśliliwszelkienadziejepodżegaczywojennych,którzyciągleliczą—inieukrywajątego—nadostojnikówkościoławPolsce,jakonaswoichsprzymierzeńców.\n",
      "W1984r.KBWuważanojeszczeoficjalniezabohaterskąjednostkę,więcMieczysławJaworskiwksiążce\"KorpusBezpieczeństwaWewnętrznego1945–1965\"(WydawnictwoMinisterstwaObronyNarodowej,Warszawa1984)podsumowywałpierwszedniKBWpoddowództwemŚwietlika:\"Wmiesiącachgrudzień1946-styczeń1947wojskaKBWprzeprowadziłynatereniekraju1057akcjioperacyjnych,wwynikuktórychzginęło-78,raniono-17,ujęto-1068członkówpodziemiaorazaresztowanoizatrzymano4344podejrzanych\".\n",
      "Wlatach1992–96byłrzecznikiemprawobywatelskich.\n",
      "Ichprojektnosinazwą„Otworzyćdrzwi”.\n",
      "Kozły:regularnemocneszóstakioporożupowyżejprzeciętnej(atakżeósmakiidziesiątaki)wIIklasiewieku,awięc4–letnieistarsze.\n",
      "AmericanCarShow-IToruńskiMiędzynarodowyZlotSamochodówAmerykańskichodbędziesięwdniach3–5majawToruniu.\n",
      "Dwatygodniepóźniejdośćdługodzwoniłdomieszkaniastryja,chwilęzaczekałsądząc,żestryjmożeśpi,apokojówkaskorzystałazokazjiiwyskoczylacośzałatwićlubzobaczyćsięzukochanym.\n",
      "-Poczekamynawyrok-mowiwiceministerJarosławBrysiewicz,któryprzywiózłjużwteczcenastępcęSzrajbera.\n",
      "-Zwłaszcza,zepalącesięlatarniezauważyłemjużkilkakrotnie.\n",
      "BógzesłałAnioła,bogozatrzymaćwostatniejminucie.\n",
      "ApańGąsowski,teżjakbyurzeczony,podniósłjąrękąispojrzałnaniązezdziwieniem.\n",
      "Zdążyłjużprzyzwyczaićsiędoconocnegorytmupsiejwachty,dopluskufali,leniwieuderzającejwstaloweburty,atakżedostojącychnakotwicachstatków—sąsiadów,którychświatłamiałwzaszęguwzroku.\n",
      "Skorotylkosiętookazałomoż1iwe,natychmiastnapisałem.\n",
      "Srebrnymedal,jednoczwartemiejsceipowołaniedokadrynarodowejnakonsultacjeiMiędzynarodowyTurniejPolishOpentotrofea,jakiezMistrzostwPolskiNiepełnosprawnychwTenisieStołowym,któreodbyłysię26–28majawOśrodkuPrzygotowańOlimpijskichwCetniewie,przywieźlizawodnicyIKSTarnobrzeg.\n",
      "Jużnieznajdujepretekstów,abyoglądaćsiędotylunadziewczynęijejpsa.\n",
      "Działalnośćks.WitaMaśnickiego-wielkiegoPolaka,wielkiegopatrioty,znakomitegoorganizatoraigazdy,wreszcierzetelnegoduszpasterza,zostałuhonorowananietylkoprzezZwiązekPodhalan.\n",
      "jatuwystępujęwobroniekomisjiśledczejipraprapracy.tejkomisjidlategożewydajemisięże.potychrożnychwydarzeniachaleteżpotychzeznaniachdzisiaj.jednakpewneelementysięskładająijużniewrócimydotegocobyłochoćtojestnapewnozapóźnoitojestbardzotragiczne\n",
      "Dojrzałośćpłciowąosiągawwieku4–5lat.\n",
      "PrzyznajecitąobrotowągwiazdęWikipediizaogromnyinieocenionywkładwartykułykreskówekJetix,CartoonNetworkorazwartykułyzfilmamiorazpracęnaddubbingiem.\n",
      "DziałaniaorientacjiBuzkaijegourzędasów,podobniejakcałegorząduświęcienampanującejkoalicjiAWS­UW,sągodnepodziwu.\n",
      "AlijewprzezrokdrażniłsięzpremieremHusejnowem,bawiłjegogafami,upokarzającymipomyłkami,niepowodzeniami,atakżejegobezsilnąwciekłością,gdyodsuwałgocorazbardziejodwładzy.\n",
      "Zupełnieniemógłoswoićsięzwidokiemsióstrubranych,każdawinnasukienkę!\n",
      "NajbliższaedycjaprogramuDolnośląskaSzkołaEkspertówCzystszejProdukcjiplanowanajestna3–7kwietnia.\n",
      "Twierdzą,żewkolejcedowyznaczeniaterminuznajdujesięwielespraw,którewypłynęłydowarszawskiegosąduwlatach1994–95,wcześniejjeszczeniżsprawapaleniaaktSBnaSzczęśliwicach.\n",
      "-Terazjużnietak,bonaświeżempowietrzusiępracujenoiwypiłosięjużprawieswojądole-usprawiedliwiałsiętrochęzażenowanyManiuś.\n",
      "Zestawyutworzonopoto,abyprzykładowokażdywczłonkówrodzinymógłskorzystaćzprogramuiwypełnićwłasnerozliczeniepodatkowe(rys.1).\n",
      "Najejwezwanianaspacerze,żebywziąłjąpodrękę,nieodzywałsięzaraz,chowałsięzapniemdrzewaiwogóletaksięurządzał,żebywuyrwaćztejokrągłej,różowejkulkilękliweskargi:\"oje,oje\"\n",
      "Równieżwwypadkunajwiększejepidemiigrypy,jakawlatach1918–1919dotknęłapołowęludzkościispowodowałaśmierć25mlnludzi,przyczynąniezwykłejzjadliwościwirusabyłnowygenpochodzącyzwirusagrypyptasiej.\n",
      "Samicakocisiępo30dniachodzapłodnienia,rzucając3–10sztukmłodych.\n",
      "Najbardziejbulwersującebyły,zdaniemdyrektor,wcalenierzadkieprzypadki,wktórychpacjentzmieniałlekarzapierwszegokontaktuw3–4miesiącepowłasnejśmierci.\n",
      "Niewiernośćjestpowszechnawśród16–21-latków-podajenajnowszyraportDurexa.\n",
      "PANIBOGUSIAposuwawjegostronęprzydziałProszepułkowniku,stotrzydzieścipięć,,kameli\",puszkasokupomarańczowego,trzy,,korned–bify\"iparawełnianychskarpetek...\n",
      "Podczasspotkaniazaktywcmpracowniczymzakładów,S.Olszowskiwyraziłzadowolenie,żedelegacjanaszaodwiedzawłaśnietenpowiat,zktórymPolakówwielełączy.\n",
      "NaukaMarksajestwszechpotężna,ponieważjestsłuszna,jestpełnaiharmonijna,dajebowiemludziomjednolityświatopogląd,niedającysiępogodzićzżadnymiprzesądami,zżadnąreacją,zżadnymiprzesądamiuciskuburżuazyjnego.\n",
      "Najednymzpocześniejszychmiejscwkatalogunaszychreformstoipostulatpowrotudospołeczno–filozoficznegopluralizmuświatopoglądowego-dopluralizmupojętegojakozasadaorganizacjispołecznegoistnienialudzi.\n",
      "SzefDumyoskarżaCzubajsa,żetoonspowodowałpowszechniekrytykowanąnominacjąbiznesmenaBorysaBieriezowskiegonastanowiskozastępcysekretarzarosyjskiejRadyBezpieczeństwa.\n",
      "Potympiciuwyleczyłemsięznerwicyitotakiej,zełykwodypowodowałtorsje...\n",
      "-Uwaga-u–wa–ga...\n",
      "Czarno–białejchuście,czarnymgetrom,opascezczerwonymkrzyżem.\n",
      "Zaczynamwyjaśniaćprzerwęwkorespondencji:Dobieramsłowaostrożnie,bowiem,żechociażtrudnościzostałyprzeżwyciężone,zdenerwowałbysięnimi.\n",
      "Żebysietennaszobchódtrzymałkupy.\n",
      "Odpółnocyłąki,pokrywającesięjesieniąłanamililiowychkwiatów-ziemonitów,zdębaminastarychgórniczychwyrobiskachibielejącąwoddalipiaskami,PustyniąBłędowską.\n",
      "Poszukiwanyprzezpolicjęmężczyznamaokoło25-30lat,szczupłą,pochylonądoprzodusylwetkę,około165–168cmwzrostu,włosyopadającenakark(szatyn),brodędośćsilniewysuniętądoprzodu.\n",
      "Niewiadomoczyciężarówkibyłbyodpowiedniozabezpieczoneprzed„gubieniem”śmieci.\n",
      "JakwynikazXIII-wiecznychdokumentówwlatach1256–1258plebanemtczewskiegokościołabyłniejakiJan.\n",
      "Krzewwysokości1,5–2m,zszerokorozkładającymisięgałęziami.\n",
      "Wprzeciwieństwiedoprorokówsprzedniewolibabilońskiej,któryczęstonegatywnieocenilisamkultiskładanewichczasachwświątyniofiaryidlategonawet,jakzwłaszczaJeremiasz,zapowiadalizniszczenie\"domuJahwe\",Aggeuszbyłcałypochłoniętytroskąnietylkooodbudowęświątyni,aleiprzywróceniewniejofiarnegokultu.\n",
      "Natomiastnaponiedziałeksynoptycyprzewidująsztormosile7–9stopniiwiatrzachodni.\n",
      "Ponieważterazmam\"zagospodarowane\"wtensposób2–3dniwtygodniu,tozastanawiamsię,czyniepoprosićoznalezieniemiwsądziejakiegośpokoju,żebyzamieszkaćtamnastałe.\n",
      "Zbadanodziałaniaprywatyzacyjnedokonywaneprzezagencjęwlatach1997–1999.\n",
      "Uczyłwszkołachpodstawowych,średnichistudium,wlatach1990–1994wiceburmistrzgminyĆmielów,1999–2000-dyrektorDomuKulturywĆmielowie,odstycznia2003rokudyrektorBiuraWystawArtystycznychwOstrowcu.\n",
      "Wczasieobradzebraniuchwaliłrezolucjępotępiającąprowokacyjnądecyzjęstojącegonausługachamerykańskichpodżegaczywojennychrządufrancuskiego,któryusunąłprof.Joliot-CuriezestanowiskaWysokiegoKomisarzadlaSprawEnergiiAtomowejorazdrugąrezolucjęobowiązującąwszystkichczłonkówStowarzyszeniadoczynnejpracywobroniepokoju.\n",
      "Wlatach1989–1991byliśmypoprostuświadkamiostatniejwdziejachświatadekolonizacji.\n",
      "Mażoretki,mającenakoncietytułumistrzowskiewPolsce,pojechałynaeuropejskichampionatdoBratysławy.\n",
      "Miejscewpierwszejjedenastcetegoklubuwywalczyłdopierowdrugiejpołowielat90.,adobrewystępywDiviziiAwsezonie1995–1996zaowocowałytransferemdoNaţionaluBukareszt.\n",
      "Zsiedmiuplacówekoświatowych,funkcjonującychwgminie,gorącązupęzwkładkamięsnąmogąjeśćjedyniedzieciuczącesięwObrytem-wSzkolePodstawowejiGimnazjum.\n",
      "Wydajność-1–2m2/kg.\n",
      "\"Ipokazali\"komentujętenopisMarianRomeyko.\n",
      "Przyjmujesię,żeorderustanowiono1listopada1705r.,choćnajnowszekwerendywdrezdeńskichipetersburskicharchiwachwskazują,żeAugustIIMocnymógłnimjużdysponować2–3latawcześniej.\n",
      "Zgłoszenianależyskładaćdo15sierpniapodnumeremtelefonu:520–59-50.\n",
      "4.Czysięgałeśkiedykowiekzarazpoobudzeniupokieliszek(\"klin\"),abypoprawićsamopoczucielub\"zabićkaca\"?\n",
      "WykładybędąsięodbywaćwAudytoriumMaximum(UniwersytetWarszawski,KrakowskiePrzedmieście),salaB,godz.17–18:30.\n",
      "Czymżezasłużyłsiepsychopata?\n",
      "TakżeLucianaFrassatiGawrońska,którapiszewprawdzieoLeonieKozłowskimjakoo\"człowiekupechowymizupełniepozbawionympowagi\"stwierdza,żebyłonpodciągłakontrolągestapo,iżestosunekdońNiemcówbyłniechętny.\n",
      "Wponiedziałek,13maja,wgodz.14.00–16.00wdelegaturzeUMGrunwaldprzyul.Matejki50dyżurpełnićbędzieradnyTadeuszJarmołowicz,wtychsamychgodzinachwdelegaturzejeżyckiej-radnaKrystynaStachowiak,awdelegaturzeNoweMiasto-AndrzejBielerzewski,wdelegaturzeWilda-PiotrSarna.\n",
      "Człowiek,októrymanapisałeśtokatolik-fanatyk,ewentualnie\"oszołom\"jakniektórzymówią.\n",
      "Licytacja,tychrzeczy,prowadzonąwramachWielkiegoŻółtegoOdrzutowegoHappeningu,rozpoczęłasięodkwoty20zł.\n",
      "BWBobiecują,zemogązagwarantowaćprodukcjęwodyznacznieprzewyższającejnormyobowiązującewUniiEuropejskiej.\n",
      "Zapewnił,zePolskabędziestarałasięjaknajbardziejułatwićPoloniikontaktyzkrajem.\n",
      "ŚwiatowaOrganizacjaZdrowia(WHO)szacuje,zeliczbaosóbumierającychnaświeciezpowoduwirusowegozapaleniawątrobytypuCniedługoprzekroczyliczbęosóbumierającychnaAIDS.\n",
      "Wjednymzpierwszychnumerówtygodnika\"Solidarność\"ukazałsięobszerny,nacałąkolumnę,wywiadzAndrzejemWajdą,któryzwierzałsięzeswoichnatajniejszychkompleksów:żewczasiewojnyniezdążyłdokonspiracji,żepóźniejzjakichśtampowodówmezdążyłdoPowstaniaWarszawskiego,żeniewziąłteżudziałuwpowojennymzmaganiuokształtPolskiniepodległej,aleteraztowszystkoodrobi,nadgoni.\n",
      "Leczchoćzdążyłwporę,rozszalałystrumieńporwałtratwęwrazzlady,którawyciągałarozpaczliwiaręcedoswegozbawcy.\n",
      "ludzie,jakdostającośtakiego,wpierwszejchwilimyślą,zeźlepoliczylizera.\n",
      "NajskuteczniejszymzawodnikiemponiedziałkowejseriimeczówbyłSzwedNaeslund,któryzdobyłtrzybramkidlaVancouverwwyjazdowymmeczuzSanJose(5–2).\n",
      "RozmieszczeniogrodówdziałkowychwPolscejestnierównomierne.\n",
      "Stanowionadoskonałedźwiękowo–dokumentacyjneuzupełnienietematunaszejrozmowy...\n",
      "Adres:ul.Lwowska5,lokal3a,telefony:825–53-94;825–44-02.\n",
      "\"Mieliśmydoczynieniazezdesperowanymi,gotowyminawszystko,porywaczami,którzyniechcielipójśćnażadneustępstwa\"-uzsadniłakcjękomandosówministersprawzagranicznychNigruAbdourahamaneHama.\n",
      "Przedwojennyetnograf,RomanReinfusstwierdzi,iinazwata,którawnaucemacharakterpojęciaetnograficznego,wpoczuciuludumazabarwieniepolityczne.\n",
      "WtrakciewczorajszejsejmikowejdebatynadProgramemRozwojuWojewództwaPomorskiegonalata2001–2006niespodziewanienajwięcejemocjiwywołałzapisdotyczącyPGR.\n",
      "Zostalioniwubiegłymtygodniuaresztowaniprzezgolenowskisąd.\n",
      "DwutlenekwęglaodznaczasięzdolnościąłatwegoprzepuszczaniapromieniowaniakrótkofalowegoSłońcaizatrzymywania(pochłanianiawpaśmie13–17«m)promieniowaniadługofalowego(podczerwonego)emitowanegoprzezpowierzchnięZiemiwkierunkuprzestrzenikosmicznej.\n",
      "Jedynecomożnamuzarzucićtoparokrotnieotarciesięopychę.\n",
      "gorącochciałabympolecićwszystkimroządnymludziomartykułwostatnimWprost\"TestzJedwabnego\"krótkitekstotymjakąburzęwsieciinietylkowywołałaksiążkapanaGrossa.\n",
      "Ostateczni,pozażartejdyskusjizwyciężyłapropozycjakierownictwaZKP.\n",
      "DziścobardziejokazaławojenkapędzlaSuchodolskiegooznaczawydatek40000–50000zł.\n",
      "WedługdanychNSZ-ZJprzedscaleniemNSZliczył70–75tys.osób,arozkazowiniepodporządkowałosięok.65tys.żołnierzy.\n",
      "Militarno–diabelskiepodziemia,wktórychczubekołówka-przedłużeniegeneralskiejręki-wykreślanamapiekształtyrzeczywistości.\n",
      "UCHODŹCAIVPułkownikRaszyn–Raszuński.\n",
      "Twierdzą,zesprawajestrozwojowa.\n",
      "Potrzebnasiećsklepów,opowierzchniok.760m2,powstaniedopierowciągu3–4lat.\n",
      "JakzapewniaKrzysztofJaroch,zawszytkomusipłacićsam.\n",
      "ResapośpieszyładoAb–Rama,czekającegoniecierpliwiewswoimnamiocie.\n",
      "Pierwszymecz:1–1,awansWisłyKraków.\n",
      "Itak,miesiącwmiesiąc,ambasadorAshobjeżdżapo8–12polskichmiasteczek,aprzyjmowanyjesttamniemaljakkról.\n",
      "NatorzepodKielcamiodbytysiępierwszewyścigisamochodowe.\n",
      "UlicąKościelnądochodzimydorynkubielskiego,przyktórymkamieniczkizXVIIiXVIIIw.(nr.2–4,8–10,12,14,15,19–21).\n",
      "Walizeczkępodarowałaadwokatowiżonazokazjiurodzin,zaśwsrodkuznajdowałasięamunicjadoosobistejbroniadwokata,specjalistywdziedzinieochronyprawczłowieka.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ostatnioplagąstałysiękradzieżesamochodówjapońskich,któredotejporynieciszyłysięwzięciemuzłodziei.\n",
      "WtymrokuwŁódzkiemskradzinojużprawie4,5tys.samochodów.\n",
      "Wstosunkudokadrykierowniczejnoweracjonalnekryteriaoceny,towysokiekwalifikacjezawodowe,czynnaakceptacjazasadustrojowychsocjalizmu,wysokiewalorymoralne,twórczainicjatywa,umiejętnośćkojarzeniazadańgospodarczychzcelamiizadaniamispołęcznymi,zdolnośćrozumienianowoczesnychprocesórozwojowychspołeczno-politycznychigospodarczych,zmysłorganizacyjny,wrażliwośćnaproblemyspołęczneorazwysokiepoczucieodpowiedzialnościidyscyplinyzarównozawodowej,jakispołęcznej.(s.38).\n",
      "wgłębiduszytłumiszpragnienieucieczkiodsamejsiebie.\n",
      "Kredytynatenceldlauczniówszkólpaństwowychzostaływcześniejuwzględnianezarównowbudżetachterenowych,jakteżwbudżetachresortówprowadzącychszkołyzawodowe.\n",
      "Wykotnastępujeco5–6tygodni.\n",
      "KilkadziesiątkilometrówodPerugii,wFoligno,masiedzibęfirmaRapanelliMacchineOlearie-spółkaakcyjnaochrakterzerodzinnym.\n",
      "Wcześniejpolicjaotrzymaładoniesienia,zePolacywymuszaliharaczwwysokości150tys.lirów(około100dolarów)jednorazowoodsprzedawcówpolskichgazetnaplacuGaribaldiegoiodprzewoźnikównatrasiePolska-Włochy.\n",
      "DoŚwiętejInkwizycjiidoHumanistów–Ateistówjednocześnie.\n",
      "-MówiPanPremieronurtachw\"Solidarności\",acoPanpawieonurtachwpartii?\n",
      "Widze,ojczulku,żetyzatopozjadałeśwszystkierozumy,iwszystkichoodmiennychpoglądachnazywachniedouczonymi.\n",
      "PrzedBożymNarodzeniemwokresieprzedbożaonarodzeniowymdominująszopki,naktóremawielunabywców.\n",
      "-Przez40latpłaciliśmyskładkinasłużbęzdrowia,ateraz,kiedyjejna-prawdępotrzebujemy,wypinająsięnanas.\n",
      "NajpierwJanuszSepiołpojechałdoBrukselinakonferencję\"Zarządzanieśrodkamistrukturalnymiwprzyszłości\"(4,96tys.zł-najdroższydotejporywyjazd),poczymKrzysztofDeszyńskiwziąłudziałwtargachinwestycyjnychwCannes(4,38tys.zł),aczłonekzarząduwojewództwaJanBereza-wtargachturystycznchwBerlinie(1tys.zł).\n",
      "Najważniejszązaletąbędziekoordynacjawszystkichpodsystemówkomunikacyjnychzkolejąpodmiejska,atakżemotoryzacjąindywidualnąorazkomunikacjąrowerową.\n",
      "WNajwyższejIzbyKontroliteżzauważonowpadkęwspółpracownikówgłowypaństwa.\n",
      "Proponuję,abySejmwdebacienadtympunktemwysłuchał10­minutowychoświadczeńwimieniuklubówi5­minutowychwimieniukół.\n",
      "Czternaścieosóbzatrułosiępałeczkamisalmonellozy,poczaswesela,któreodbyłosięwminionyweekendwPuławach.\n",
      "-Oninieznająinnychmetodrozwiązywaniaproblemów,takichjakrozmowalubustępstwo,uznawanezaoznakęsłabości-mówiAlaksandraAdamek.\n",
      "Bowprzecieżwmomenciepisaniakolejnegodziełaautorjestjużinnaosobą?\n",
      "-Onajestdlamnienawagęzłotainiezostawięjejsamej,choćbymjechaćmiałzaniądosamejTreblinki6>.\n",
      "Mat.21:12–17iJana2:13–22\n",
      "-LeżynaszestareNakło,odpołudnianadłąkamiwNadnoteckiejDolnieodpółnocyzaśglebąurodzajnąsłynie.\n",
      "Tak,tak...lekkilennalato,anazimeosiemdziesiątka...nawetniczego.\n",
      "Firmagwarantujejakość,atechnologiaDVDpozwalazmieścićnajednejpłycieolbrzymimateriał(m.inaż5godzinfilmów).\n",
      "Dochodzi5–taizaległacisza.\n",
      "SądgospodarczywMińskunakazałzamknięcienajwiększejbiałoruskiejniezależnejgazety\"Swaboda\"za\"podżeganiedonienawiścimiędzyspołeczenstwemawładzami\".\n",
      "WsobotęnaBałtykuwiatrpowiejezpołudniowegozachoduzsiłą5–6stopniwskaliBeauforta,okresamibędziedochodziłdo7stopni.\n",
      "Dokument,októregonalezieniupiszetygodnik\"SundayMirror\",zostałprzygotowanyprzezgen.KlausaNaumannadlasekretarzageneralnegoNATO.\n",
      "Jesteśstraszliweniedouczony.\n",
      "WuroczystościwzięliudziałczłonkowieZarząduMiasta,radni,przedstawicielePaństwowegoFunduszeuRehabilitacjiOsóbNiepełnosprawnychorazFundacji\"WspólnotaDobrejWoli.\"\n",
      "Starostwowniosłopozewdasądu.\n",
      "Pozatymsadzę,żetakapostawadodajeotuchytym,którzyteżsąchorzynatęchorobeiwidzą,żeKamilniedajesierakowi.\n",
      "Sosozaczyniałpięknym,czystymgłosem:\"Jaostrzęcię,ostrzę,mójsierpie,znaszegotyśżelaza\".\n",
      "Dwarazyogłaszanoprzetagnawykonawstwoidwukrotnieniktniezłożyłofertynainwestycjęwartą1350tys.zł.\n",
      "Urloptennieprzerywawięcuprawnieńpracownikadonagrodyidojejwysokościuzależnionejodstażupracywtymzakładzie,chociażsamegookresuurlopubezpłatnegoniewliczasięodokresupracy,odktóregozależąuprawnieniapracownicze,wtymtrzynastka.\n",
      "Wtejpieśnimamywszystkodetaliczniepodaneznazwiskamyagienciakówidatawypadku.\n",
      "ByłaMissAmerica,37-letniaElizabethWardGracen,któramazeznawaćwprocesiewytoczonymprezydentowiClintonowiprzezPaulęJones,oświadczyła,zeuprawiałasekszBillemClintonemwczasach,kiedybyłjeszczegubernatoremstanuArkansas,aleodbywałsiętozaobopólnązgodą.\n",
      "ItrudnoopiękniejszyjegowyrazniżtelinijkijednejzódHoracego(65–8p.n.e.):\n",
      "Zdenerwowanydługoniemógłwydobyćżkieszenikluczadoswegopokoju,gdytymczasemzzadrzwidobiegałnatarczywydzwonektelefonu.\n",
      "Drugiwtymczasiezacząłsiębacznierozglądaćomieszkaniu.\n",
      "Wieluklientówunikkupowaniawędlinwkawałku,jakrównieżdrogichserów,ponieważjesttonieekonomiczne(wdomu,przypomocynożaniełatwopokroićjewcienkiejakpergaminplasterki).\n",
      "Wmeczetachikościołachmodląsię,arządzadłużyłsięnakolejnepólmiliardadolarów,kupującweFrancji,RFNiUSAgeneratorypracującenagaz,któregowEgipciejestpoddostatkiem.\n",
      "NaekranieTV,nazatrzymanejstop–klatceJurkaKileraidąnapisykońcoweprogramu.\n",
      "WiarygodnośćsondażydotyczącychSLDpozostawiawieledożyczenia,bowynikiwyborówzarównodoParlamentuEuropejskiego,jakiiparlamentarnychzasadniczoróżniłysięodprognoz.\n",
      "Iskrajnaopiniazdrugiejstrony-nastapikoniecświata,apowejściuokażesię,żeanijedno,anidrugie.\n",
      "Badanietakiejestobowiązkoweuwszystkichwcześniakówprzebywajacychwinkubatorze,ponieważpozwalawykryćchorobę,rozwijającąsięnaskutekuszkodzeniaoczuprzeztlen,zwanąretinopatią.\n",
      "Zafarbowanieśredniopo20złotych,balejaż-30–40złotych.\n",
      "Broniłeksmitowanychnabruk,naprawiającbłędyprzyjętejprzezkoalicjęSLD­PSLustawy,grzmiałnaglobalistówiświeżychkrajowych,drapieżnychkapitalistów.\n",
      "Niestetykażdapassamatodosiebie,żemusisieskończyć.\n",
      "Sątom.in.BernardGrzimek(1909–1987),wybitnyzoolog;KonradBloch(ur.1912),biochemik,laureatnagrodyNoblaw1964,mieszkającywUSA.\n",
      "Wostatninocbędziemożnaspaćwewłasnoręczniezrobionymdomku,organizatorzyzapewniająognisko,kiełbaskiiwybornązabawę.\n",
      "STUDENT-Wyzywampananapojedynek,pif–paf!\n",
      "-Tak!-zawołałAb–Ramzmocą.\n",
      "Wczerwcu1982roku-pierwszymrokustanuwojennego,generałWojciechJaruzelskiotrzymałwcodziennejpoczcielist,nadesłanyprzezPaulinęKoziakzSosnowca–ZagórzezamieszkałąprzyulicyPKWN114.\n",
      "Osoba,któracierpinachorobępsychocznąróżnisięodfaceta,którypoprosturozmumpostradałizabijadlaprzyjemnościiwłasnejsatysfakcji.\n",
      "Innewarszawskieosiedląrównieżpróbująpowołaćradymieszkańców.\n",
      "Algierskaprasapodaje,żeislamiścistosujązawszętęsamątaktykę.\n",
      "-Józwato...noJózwa...-roze?mia?asi?bezradna.\n",
      "MinisterAntoniMacierewicz,zeznającywśrodęprzedkomisją,oskarżyłministraWachowskiegooszantaż,ktoregocelemmiałobyćniedopuszczeniedoujawnieniamateriałówobciążającychLechaWałęsęokontaktyzesłużbąbezpieczeństwawlatach70.\n",
      "WmyślnowelizowanejobecnieustawyoBFGkwotagwarantowanaprzezfunduszbędziesystematycznierosnąć,osiągającw2004r.europejskąwysokość15–20tys.ECU(obecnie5tys.ECU).\n",
      "Proszeułożyćmicoś,żebyludziezębamizgrzytali,włosydarli,płakali,aleirównocześniewrogaszukali...\n",
      "InformacjewWydzialePromocjiUrzęduMiasta,pok.307,tel.22–25.\n",
      "AwansowalidoczwartejrundyPucharuUEFA,gromiącwGelsenkirchenSchalke04,zespół,którywpoprzednimetapierozgrywekwyeliminowałLegięWarszawa(3–2,0–0).\n",
      "Niemusieliinterweniować,angażowaćswychsiłzbrojnychwEuropieŚrodkowo–Wschodniej,zakłócaćstosunkówzZachodem.\n",
      "-Paniewładzuchna,budzi!-usiłowałuściskaćprzedstawicielamilicjiManiuś.\n",
      "Dzieckopoprzyjściunaświatjestkładzionemamienabrzuchna1–3minuty,awciągu2godzinprzystawianedopiersi.\n",
      "Narynkukrążyłyplotki,zenaspotkaniuRadyPolitykiPieniężnejzrządemustalono,iżNarodowyBankPolskibędzieinterweniowałnarynkuwalutowym,bydoprowadzićdospadkuwartościzłotego.\n",
      "WG:Przyznapanjednak,zebyłatopróbapogodzeniatego,cojednostkowe,ztym,coogólne.\n",
      "NatomiastMrozowskiistotniewałkoniłsięicałajegodziałalnośćliterackawciągusześciulat(1934–1939)ograniczyłasiędojednegoszczupłegotomikuwierszypt.\"Dobranoc...dobranoc...\".\n",
      "-Nicchciałamciętuzapraszać,alejeżelijużmnieznalazłeśprzypomocytegozdrajcyDidiera...\n",
      "TaWisłapodToruniemniepo–płyniedomorza...taksobie...wodazawodą...jacisłodkiejbuzipodom...aleza–wró-ciiwstęgątomiastoułańskieotoczy.\n",
      "Wapiennaszosaprzecinałabiałąkreskącałytenkrajobraz,byzniknąćzaBolesławiem,wRoznowskimlesieprzedStarymOlkuszem.\n",
      "Chronićtrzebaglebęprzedwyciekamizwielkichzbiornikówopojemności40–50m3,ściekamizmyjniibaru(nawet10m3nadobę),czynasząnieostrożnościąpodczastankowania.\n",
      "CIEEE–KAWE!\n",
      "287\n"
     ]
    }
   ],
   "source": [
    "mmm = 0\n",
    "for sent in skladnica_sents:\n",
    "    if not sent in rejected_sents:\n",
    "        print(sent)\n",
    "        mmm += 1\n",
    "print(mmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Program \"Nieletni a prawo\" adresowany jest przede wszytskim do uczniów gimnazjów, jego celem jest przekazanie młodzieży w przystęny sposób wiedzy na temat odpowiedzialności za popełnianie czynów niezgodnych z prawem.'.replace(' ', '') == 'Program\"Nieletniaprawo\"adresowanyjestprzedewszytskimdouczniówgimnazjów,jegocelemjestprzekazaniemłodzieżywprzystęnysposóbwiedzynatematodpowiedzialnościzapopełnianieczynówniezgodnychzprawem.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for fragm in fragms:\n",
    "    if 'młodzież' in fragm and 'prawo' in 'fragm':\n",
    "        print(fragm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zatrzasnąć', 'drzwi', 'od', 'mieszkanie', ',', 'dwa', 'raz', 'przekręcić', 'klucz', ',', 'nacisnąć', 'klamka', ',', 'by', 'sprawdzić', ',', 'czy', 'dobrze', 'zamknąć', ',', 'zbiec', 'po', 'schody', ',', 'minąć', 'furtka', ',', 'także', 'on', 'zamknąć', ',', 'i', 'znaleźć się', 'na', 'wąski', 'uliczka', 'między', 'ogródek', ',', 'gdzie', 'drzemać', 'w', 'majowy', 'słońce', 'trójkątny', 'ciemnozielony', 'świerk', ',', 'jaki', 'być', 'w pobliżu', 'on', 'dom', '.', 'bohater', 'powieść', 'Paźniewski', 'być', 'miasto', ',', 'Krzemieniec', '.', 'jak', 'za', 'czas', 'Słowacki', 'funkcjonować', 'liceum', 'i', 'płynąć', 'Ikwa', '.', 'Krzemieniec', 'powieściowy', 'być', 'tamten', 'Krzemieniec', ',', 'ale', 'być', 'także', 'miasto', 'wywołać', 'z', 'osobisty', 'pamięć', 'Paźniewski', '.', 'swój', 'droga', 'do', 'ten', 'miasto', 'autor', '„', 'krótki', 'dzień', '”', 'zacząć', 'z daleka', 'bardzo', '.', '„', 'nigdy', 'być', 'w', 'ten', 'dom', ',', 'a', 'przecież', 'wszystko', 'pamiętać', 'doskonale', '”', '.', 'ale', 'dzisiaj', '?', 'jaki', 'dzisiaj', 'odegrać', 'rola', 'poetyka', 'Przyboś', '?', 'oczywiście', ',', 'już', 'sam', 'fakt', 'on', 'istnieć', 'być', 'wartość', '.', 'nasz', 'literatura', ',', 'bogaty', 'w', 'improwizacja', 'i', 'w', 'akt', 'strzelisty', ',', 'być', 'ubogi', 'w', 'teoria', '.', 'rola', 'teoretyk', 'spełniać', 'felietonista', ',', 'który', 'co', 'tydzień', 'fundować', 'szkoła', 'i', 'formułować', 'program', '.', 'dlatego', 'założenie', 'teoretyczny', 'Przyboś', 'obok', 'teoria', 'Peiper', 'i', 'Witkacy', ',', 'a', 'równolegle', 'do', 'propozycja', 'system', 'Irzykowski', 'i', 'Sandauer', ',', 'stanowić', 'kapitał', 'nasz', 'myśl', 'krytyczny', ',', 'naturalny', 'fundament', 'każdy', 'twórczość', '.', 'to', 'oczywistość', '.', 'Halina', 'Auderska', 'w', 'wszystek', 'książka', 'kazać', 'swój', 'bohater', 'szukać', 'tożsamość', '.', 'w', '„', 'babi', 'lato', '”', 'mieć', 'odwaga', 'uznać', 'za', 'istotny', 'kryterium', 'tożsamość', 'poczucie', 'przynależność', 'nie, nie, lecz', 'do', 'idea', 'do', 'kultura', 'i', 'mit', 'narodowy', 'do', 'to', ',', 'co', 'być', 'podstawa', 'byt', 'każdy', 'człowieczeństwo', '.', 'miejsce', 'na', 'ziemia', ',', 'konkret', 'fizyczny', 'i', 'społeczny', 'jednocześnie', 'być', 'to', ',', 'co', 'stanowić', 'o', 'wymiar', 'życie', 'i', 'los', '.', 'Paźniewski', 'w', '„', 'krótki', 'dzień', '”', 'ofiarować', 'Kresy', 'nie', 'mało', ',', 'niż', 'z', 'on', 'zaczerpnąć', '.', 'zatrzymać', 'potop', '.', 'zamówić', 'kataklizm', '.', 'stworzyć', 'wizja', 'oczekiwanie', ',', 'wizja', 'spokój', 'przed', 'burza', '.', 'z', 'napięcie', 'czekać', 'na', 'chwila', ',', 'który', 'być', 'chwila', 'decydować', 'o', 'los', 'bohater', '.', 'cóż za', 'ulga', '.', 'mijać', 'ostatni', 'zdanie', 'powieść', '.', 'co za', 'wspaniały', 'książka', '!', 'ocalać', '!', '„plama”', 'Piętak', ',', 'jeden', 'spośród', 'kilka', 'znakomity', 'współczesny', 'powieść', ',', 'także', 'ze względu na', 'on', 'zaklasyfikować', 'wraz z', 'cały', 'twórczość', 'ten', 'pisarz', 'do', 'nurt', 'wiejski', ',', 'mieć', 'w', 'odbiór', 'powszechny', 'ten', 'ranga', ',', 'jaki', 'rzeczywiście', 'posiadać', '.', 'wszystko', 'co', 'Piętak', 'wynieść', 'z', 'chłopski', 'szkoła', 'wyobraźnia', ',', 'zaowocować', 'w', '„plama”', 'wysoki', 'subtelność', 'psychologiczny', ',', 'na', 'jaki', 'stać', 'literatura', '.', 'to', 'już', 'wątpliwość', 'religijny', ',,', 'ten', 'wątpliwość', 'pierwszy', 'stopień', 'wtajemniczenie', 'w', 'sprawa', 'świat', 'wątpliwość', '„', 'niebo', 'w', 'płomień', '”', 'czy', '„', 'Jan', 'Barois', '”', '.', 'tu', 'chodzić', 'o', 'sensowność', 'dogmat', 'czy', 'ścisłość', 'religijny', 'wyobrażenie', ',', 'chodzić', 'już', 'o', 'religia', ',', 'o', 'tajemnica', 'stworzenie', ',', 'ale', 'o', 'norma', 'etyczny', '.', 'kto', 'on', 'ustanowić', ',', 'kiedy', 'Bóg', 'zabraknąć', '?']\n"
     ]
    }
   ],
   "source": [
    "print(fragms[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_line = True\n",
    "word_n = 0\n",
    "word_idx = {}\n",
    "\n",
    "# we'll read those from the data file\n",
    "vecs_count = 0\n",
    "vecs_dim = 100\n",
    "\n",
    "with open(vecs_path+\"data\") as vecs_file:\n",
    "    for line in vecs_file:\n",
    "        if first_line:\n",
    "            # Read metadata.\n",
    "            vecs_count = int(line.split(' ')[0])\n",
    "            vecs_dim = int(line.split(' ')[1])\n",
    "            first_line = False\n",
    "            continue\n",
    "        # Read lemma base forms.\n",
    "        word_idx[line.split(' ')[0]] = word_n\n",
    "        word_n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vecs = np.loadtxt(vecs_path+\"data\", encoding=\"utf-8\",\n",
    "                       dtype=np.float32, # tensorflow's requirement\n",
    "                       skiprows=1, usecols=tuple(range(1, vecs_dim+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add the dummy boundary/unknown marker.\n",
    "word_vecs = np.vstack([word_vecs, np.zeros((1,vecs_dim), dtype=np.float32)])\n",
    "vecs_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_id(word):\n",
    "    return word_idx[word] if word in word_idx else vecs_count-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1549322"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_id('ffggf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1549323, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs_count, vecs_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_word = {v: k for k, v in word_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['niewakacyjny',\n",
       " 'wysiadl',\n",
       " 'Beziehungen',\n",
       " 'Collaquo',\n",
       " 'Duszanowi',\n",
       " '0ALinkizew',\n",
       " 'powiązan',\n",
       " 'Piesztanach',\n",
       " 'matriału']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from random import randint\n",
    "#neg_sample = []\n",
    "#while len(neg_sample) < 1 + (2 * window_size):\n",
    "#    neg_sample.append(randint(0, vecs_count-1))\n",
    "#[idx_word[n] for n in neg_sample]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/lib64/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM, Embedding\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Training corpus preparation.\n",
    "#\n",
    "\n",
    "from random import randint\n",
    "from math import floor\n",
    "\n",
    "# We need a special token for cases when the target word is near the start or end of sentence.\n",
    "bound_token_id = vecs_count - 1 # the zero additional vector\n",
    "\n",
    "sample_n = 0\n",
    "\n",
    "train = np.zeros(((words_count + words_count // points_per_neg_sample) * corp_runs,\n",
    "                  window_size * 2 + 1), dtype='int')\n",
    "labels = np.ones(((words_count + words_count // points_per_neg_sample) * corp_runs,),\n",
    "                dtype='int')\n",
    "\n",
    "for run_n in range(corp_runs):\n",
    "    fragm_n = 0\n",
    "    word_n = 0\n",
    "        \n",
    "    while fragm_n < len(fragms) and sample_n < train.shape[0]:\n",
    "        \n",
    "        # The positive sample.\n",
    "        train[sample_n, window_size] = word_id(fragms[fragm_n][word_n])\n",
    "        \n",
    "        for j in range(window_size):\n",
    "            train[sample_n, j] = (word_id(fragms[fragm_n][word_n-j-1]) if word_n-j-1 >= 0\n",
    "                                  else bound_token_id)\n",
    "            train[sample_n, window_size+j+1] = (word_id(fragms[fragm_n][word_n+j+1])\n",
    "                                                if word_n+j+1 < len(fragms[fragm_n])\n",
    "                                                else bound_token_id)\n",
    "        \n",
    "        # The negative sample.\n",
    "        sample_n += 1\n",
    "        train[sample_n,] = np.random.permutation(train[sample_n-1,])\n",
    "        # replace two random words\n",
    "        train[sample_n, randint(0, window_size*2)] = randint(0, vecs_count-1)\n",
    "        train[sample_n, randint(0, window_size*2)] = randint(0, vecs_count-1)\n",
    "        labels[sample_n] = 0.0\n",
    "                \n",
    "        sample_n += 1\n",
    "        word_n += 1\n",
    "        try:\n",
    "            while word_n == len(fragms[fragm_n]):\n",
    "                word_n = 0\n",
    "                fragm_n += 1\n",
    "        except IndexError: # happens on the end of the corpus\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()                                                                                               \n",
    "model.add(Embedding(vecs_count,\n",
    "                    vecs_dim,\n",
    "                    weights=[word_vecs],\n",
    "                    input_length=window_size * 2 + 1,\n",
    "                    trainable=False))                                                                              \n",
    "model.add(LSTM(96))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "opt = SGD(lr=learning_rate, decay=reg_rate)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3969276/3969276 [==============================] - 2386s 601us/step - loss: 0.2058 - acc: 0.9217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0d38738780>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.models.Sequential at 0x7f0ac44f5978>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  708, 21345,  5375,     8,   724,     0,   322,   164,    16])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.asarray([word_id(w) for w in\n",
    "                ['Niemcy', 'znienacka', 'wkroczyć', 'do', 'Francja', 'w', 'maj', 'kolejny', 'rok']],\n",
    "               dtype='int')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,  2605,   619,   123,  1300, 34251,     3,    92,  9152])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.asarray([word_id(w) for w in\n",
    "                ['kot', 'zimny', 'okrągły', 'start', 'do', 'w', 'Czechy', 'wykres', 'klub']],\n",
    "               dtype='int')\n",
    "Y\n",
    "Y = np.asarray([word_id(w) for w in\n",
    "                ['w', 'zimny', 'miesiąc', 'zakładać', 'żołnierz', 'do', 'szkoła', 'każdy', 'dzień']],\n",
    "               dtype='int')\n",
    "Y\n",
    "Y = np.asarray([word_id(w) for w in\n",
    "                ['w', 'kąt', 'izba', 'stać', 'urządzenie', 'kaflowy', 'z', 'wiele', 'garnek']],\n",
    "               dtype='int')\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2646184, 9)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9920195]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.atleast_2d(Y), batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from math import floor\n",
    "\n",
    "fragms_step = 1 # set to higher values if we want to skip some proportion of fragments\n",
    "# We need a special token for cases when the target word is near the start or end of sentence.\n",
    "bound_token_id = vecs_count - 1 # the zero additional vector\n",
    "\n",
    "def skipgram_batches():\n",
    "    for run_n in range(corp_runs):\n",
    "        sent_n = 0\n",
    "        word_n = 0\n",
    "        \n",
    "        target_n = 0 # relative to the current batch\n",
    "        \n",
    "        batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "        labels = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "        \n",
    "        while sent_n < len(fragms):\n",
    "            for j in range(window_size):\n",
    "                batch[target_n*window_size+j] = word_id(fragms[sent_n][word_n])\n",
    "            # \"Good\" examples - words near the target (we will let TensorFlow randomize the \"bad\" ones)\n",
    "            for j in range(window_size // 2):\n",
    "                labels[target_n*window_size+j*2] = (word_id(fragms[sent_n][word_n-j-1]) if word_n-j-1 >= 0\n",
    "                                                       else bound_token_id)\n",
    "                labels[target_n*window_size+j*2+1] = (word_id(fragms[sent_n][word_n+j+1])\n",
    "                                                         if word_n+j+1 < len(fragms[sent_n])\n",
    "                                                         else bound_token_id)\n",
    "                \n",
    "            target_n += 1\n",
    "            if target_n == (batch_size // window_size):\n",
    "                yield batch, labels\n",
    "                batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "                labels = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "                target_n = 0\n",
    "                \n",
    "            word_n += 1\n",
    "            try:\n",
    "                while word_n == len(fragms[sent_n]):\n",
    "                    word_n = 0\n",
    "                    sent_n += fragms_step\n",
    "                    if (floor(sent_n / len(fragms) * 10)\n",
    "                        > floor((sent_n-fragms_step) / len(fragms) * 10)):\n",
    "                        print('{}0%'.format(floor(sent_n / len(fragms) * 10)), end=' ')\n",
    "            except IndexError: # happens on the end of the corpus\n",
    "                break\n",
    "                \n",
    "        batch[target_n:] = 0.0\n",
    "        labels[target_n:, :] = 0.0\n",
    "        yield batch, labels#, (run_n == corp_runs - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classif_W1 = Variable(torch.randn(vecs_dim*2, vecs_dim*2), requires_grad=True)\n",
    "classif_b1 = Variable(torch.randn(1, vecs_dim*2), requires_grad=True)\n",
    "classif_W2 = Variable(torch.randn(vecs_dim*2, 1), requires_grad=True)\n",
    "classif_b2 = Variable(torch.randn(1, 1), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start: 2018-02-21 22:48:45.389630\n",
      "Loss: Variable containing:\n",
      " 319.7979\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss: Variable containing:\n",
      " 1.2369\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss: Variable containing:\n",
      " 1.2369\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss: Variable containing:\n",
      " 1.2370\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss: Variable containing:\n",
      " 1.2371\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss: Variable containing:\n",
      " 1.2371\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss: Variable containing:\n",
      " 1.2368\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "10% Loss: Variable containing:\n",
      " 1.2368\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "20% 30% 40% Loss: Variable containing:\n",
      " 1.2369\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "50% Loss: Variable containing:\n",
      " 1.2370\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss: Variable containing:\n",
      " 1.2369\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss: Variable containing:\n",
      " 1.2369\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "60% Loss: Variable containing:\n",
      " 1.2370\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss: Variable containing:\n",
      " 1.2367\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss: Variable containing:\n",
      " 1.2368\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "70% Loss: Variable containing:\n",
      " 1.2369\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "80% 90% Loss: Variable containing:\n",
      " 1.2368\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss: Variable containing:\n",
      " 1.2370\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss: Variable containing:\n",
      " 1.2368\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Loss: Variable containing:\n",
      " 1.2370\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "100% "
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-f7a3d9d7d8c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training start:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskipgram_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m# We get word indices, convert them to vectors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_vecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# main words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-d3f938c02850>\u001b[0m in \u001b[0;36mskipgram_batches\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_n\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_n\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;31m#, (run_n == corp_runs - 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "batch_n = 0\n",
    "\n",
    "print('Training start:', datetime.datetime.now())\n",
    "for batch, labels in skipgram_batches():\n",
    "    # We get word indices, convert them to vectors.\n",
    "    batch = word_vecs[batch] # main words\n",
    "    pos_examples = word_vecs[labels]\n",
    "    neg_examples = word_vecs[np.random.randint(vecs_count, size=pos_examples.shape)]\n",
    "    \n",
    "    pos_batch = Variable(torch.Tensor(np.hstack((batch, pos_examples))), requires_grad=False)\n",
    "    pos_preds = ((pos_batch.mm(classif_W1) + classif_b1).sigmoid().mm(classif_W2)\n",
    "                      + classif_b2).sigmoid()\n",
    "    neg_batch = Variable(torch.Tensor(np.hstack((batch, pos_examples))), requires_grad=False)\n",
    "    neg_preds = (((neg_batch.mm(classif_W1) + classif_b1).sigmoid()).mm(classif_W2)\n",
    "                      + classif_b2).sigmoid()\n",
    "    \n",
    "    loss1 = ((- pos_preds).sum() / batch_size +\n",
    "             # regularization:\n",
    "                (classif_W1.abs().sum() + classif_b1.abs().sum() +\n",
    "                 classif_W2.abs().sum() + classif_b2.abs().sum())\n",
    "                * reg_rate)\n",
    "    loss1.backward()\n",
    "    loss2 = (neg_preds.sum() / (batch_size * 10) +\n",
    "             # regularization:\n",
    "                (classif_W1.abs().sum() + classif_b1.abs().sum() +\n",
    "                 classif_W2.abs().sum() + classif_b2.abs().sum())\n",
    "                * reg_rate)\n",
    "    loss2.backward()\n",
    "    if batch_n % 25000 == 0:\n",
    "        print(\"Loss: {}\".format(loss1 + loss2))\n",
    "        #print(pos_preds)\n",
    "        #print(neg_preds)\n",
    "    \n",
    "    classif_W1.data = learning_rate * classif_W1.grad.data\n",
    "    classif_b1.data = learning_rate * classif_b1.grad.data\n",
    "    classif_W2.data = learning_rate * classif_W2.grad.data\n",
    "    classif_b2.data = learning_rate * classif_b2.grad.data\n",
    "    classif_W1.grad.data.zero_()\n",
    "    classif_b1.grad.data.zero_()\n",
    "    classif_W2.grad.data.zero_()\n",
    "    classif_b2.grad.data.zero_()\n",
    "    \n",
    "    batch_n += 1\n",
    "print('Training end:', datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "word = \"być\"\n",
    "softmax = torch.nn.Softmax()\n",
    "vec = Variable(torch.Tensor(\n",
    "            np.hstack((np.broadcast_to(word_vecs[word_id(word), :], (vecs_count, vecs_dim)),\n",
    "                       word_vecs))\n",
    "         ), requires_grad=False)\n",
    "pred = softmax((((vec.mm(classif_W1) + classif_b1).sigmoid()).mm(classif_W2)\n",
    "                      + classif_b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.3104\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow (currently unused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    # Model parameters: word embeddings and model weights & biases for each word.\n",
    "    embeddings = tf.Variable(tf.random_uniform([vecs_count, vecs_dim], -1.0, 1.0))\n",
    "    nce_weights = tf.Variable(tf.truncated_normal([vecs_count, vecs_dim],\n",
    "                                                  stddev=1.0 / math.sqrt(vecs_dim)))\n",
    "    nce_biases = tf.Variable(tf.zeros([vecs_count]))\n",
    "    \n",
    "    # The computation graph.\n",
    "    inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "    labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "    embedding_layer = tf.nn.embedding_lookup(embeddings, inputs)\n",
    "    # Note that word2vec has no \"real\" hidden layers apart from the embedding.\n",
    "    \n",
    "    # Number of random words to sample apart from the true target; the model should learn to\n",
    "    # assign low probability to them given the context.\n",
    "    negative_samples_n = batch_size\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.nce_loss(weights=nce_weights,\n",
    "                                         biases=nce_biases,\n",
    "                                         labels=labels,\n",
    "                                         inputs=embedding_layer,\n",
    "                                         num_sampled=negative_samples_n,\n",
    "                                         num_classes=vecs_count))\n",
    "    # Vanilla SGD seems to work here better - since we train practically a different word vector\n",
    "    # each time, decaying momentum hinders training of later vectors before they can even be shown\n",
    "    # to the net, especially in the case of Adagrad's vanishing updates.\n",
    "    # (NOTE!) here we DO NOT touch the embeddings, we want to only learn nce_weights and biases!\n",
    "    optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start: 2018-02-07 19:02:51.118178\n",
      "(loss: 675.9548950195312) 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% 10% 20% 30% 40% 50% 60% 70% 80% (loss: 2.3737263679504395) 90% 100% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% 10% 20% 30% 40% 50% (loss: 1.877175211906433) 60% 70% 80% 90% 100% Final loss: 2.2043426\n",
      "Training end: 2018-02-07 19:25:10.739346\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "# we want to use those later:\n",
    "trained_nce_weights = []\n",
    "trained_nce_biases = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print('Training start:', datetime.datetime.now())\n",
    "    tf.global_variables_initializer().run()\n",
    "    i = 0\n",
    "    for batch_inputs, batch_labels, is_last in skipgram_batches():\n",
    "        if is_last:\n",
    "            _, loss_val, trained_nce_weights, trained_nce_biases = sess.run(\n",
    "                [optimizer, loss, nce_weights, nce_biases],\n",
    "                feed_dict={inputs: batch_inputs, labels: batch_labels})\n",
    "            print('Final loss:', loss_val)\n",
    "            print('Training end:', datetime.datetime.now())\n",
    "        else:\n",
    "            _, loss_val = sess.run([optimizer, loss], feed_dict={inputs: batch_inputs,\n",
    "                                                             labels: batch_labels})\n",
    "            if (i % 250000 == 0):\n",
    "                print('(loss: {})'.format(loss_val), end=' ')\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55766, 100), (55766,))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_nce_weights.shape, trained_nce_biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_words = [rev_word_idx[i] if i < vecs_count-1 else ' ' for i in range(idxs.shape[1])][::-1] # reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word = \"być\"\n",
    "vec = np.reshape(word_vecs[word_id(word), :], (1, vecs_dim))\n",
    "prediction = np.dot(vec, np.transpose(trained_nce_weights))\n",
    "prediction = np.add(prediction, trained_nce_biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31166"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_id(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idxs = np.argsort(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 55766)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " 'kazirodczy',\n",
       " 'teori',\n",
       " 'nscrossen',\n",
       " 'Bierówka',\n",
       " 'hat-tricka',\n",
       " 'bazgrać',\n",
       " 'rozgościć',\n",
       " 'niezmącony',\n",
       " 'Valle',\n",
       " 'łajać',\n",
       " '7-13',\n",
       " 'Brett',\n",
       " 'Silesii',\n",
       " 'zaliczkowy',\n",
       " 'Wojcieszów',\n",
       " 'Sław',\n",
       " 'odwiecznie',\n",
       " '²',\n",
       " 'kwalifikator',\n",
       " 'stulejka',\n",
       " 'Eugen',\n",
       " 'avi',\n",
       " 'abażur',\n",
       " 'wydeptywać',\n",
       " 'Dederko',\n",
       " 'płatowiec',\n",
       " 'niedosłuch',\n",
       " 'Kornasiewicz',\n",
       " 'Krysiewicza',\n",
       " 'Besbir',\n",
       " 'separować',\n",
       " 'Rumsfeld',\n",
       " 'Kurowo',\n",
       " 'obstrzał',\n",
       " 'Galapagos',\n",
       " 'odmownie',\n",
       " 'Dłutów',\n",
       " 'wolnomularski',\n",
       " 'Liptak',\n",
       " 'zbutwiały',\n",
       " 'Gliwa',\n",
       " 'Johana',\n",
       " 'tia',\n",
       " 'Cieślikowski',\n",
       " 'doktrynerstwo',\n",
       " 'nieokrzesany',\n",
       " '1440',\n",
       " 'EG',\n",
       " 'Lokia',\n",
       " 'Elo',\n",
       " 'budzetu',\n",
       " 'UFK',\n",
       " '70-300',\n",
       " 'wszystkowiedzący',\n",
       " 'Burger',\n",
       " 'ankiete',\n",
       " 'Małastowskiej',\n",
       " 'Kubiś',\n",
       " 'rozpustny',\n",
       " 'Galos',\n",
       " '75-300',\n",
       " 'JKK',\n",
       " '637-12-23',\n",
       " 'płaszczak',\n",
       " 'wine',\n",
       " 'ats',\n",
       " 'żupan',\n",
       " 'zauwazyl',\n",
       " 'wykusz',\n",
       " \"There's\",\n",
       " 'Solar',\n",
       " 'skamleć',\n",
       " 'szczotkować',\n",
       " 'Karamazow',\n",
       " 'gromnica',\n",
       " 'dysgrafia',\n",
       " 'łyżworolka',\n",
       " 'Zarzycka',\n",
       " 'Muskat',\n",
       " 'choleryk',\n",
       " 'Matteo',\n",
       " 'Basiak',\n",
       " 'browning',\n",
       " 'wywiadownia',\n",
       " 'Ravensbrück',\n",
       " 'Lubomirska',\n",
       " 'KDE',\n",
       " 'Claus',\n",
       " 'Hucina',\n",
       " 'Wizygot',\n",
       " 'Hg',\n",
       " 'Knysok',\n",
       " 'zaparzać',\n",
       " 'odbezpieczyć',\n",
       " 'Sanders',\n",
       " 'Kriegsmarine',\n",
       " 'Record',\n",
       " 'zapamiętale',\n",
       " 'Paper']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_words[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
